{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1\n",
    "\n",
    "Deep neural networks have been a major breakthrough in the world of computer science. These networks have allowed\n",
    "amazing discoveries to occur with image and audio processing, as well as other interesting topics. However, while\n",
    "deep learning is all the rage these days, I don't think it will stay that way. I think it will stick around and be\n",
    "used when necessary, but I don't think that in 10 years every single data operation will involve deep learning, and\n",
    "there are a couple reasons why I believe this.\n",
    "\n",
    "My first reason for believing this is because of the complexity involved in setting up a deep neural network. The\n",
    "network needs to have the right number of layers and hyperparameters, and fine tuning these details can take a lot of\n",
    "effort (and therefore money) which isn't attractive to a lot of companies. Even if a company sets up a deep neural\n",
    "network, they still have to train this network which is my next reason. Training these networks can take multiple\n",
    "weeks and require a ton of processing power. Whereas if the company sticks with a traditional machine learning model\n",
    "they can quickly run it on a laptop. My final reason involves the applicability of deep neural networks. In a lot of\n",
    "business problems, basic machine learning works just fine because the company has access to high quality business data.\n",
    "Therefore, it would be overkill to apply deep learning to these situations. Rather, deep neural networks will have a\n",
    "bigger influence in the areas of lower quality data like images and audio. So, I think deep neural networks will be\n",
    "used in the future, but rather than being on the top of the mountain I think they will be used alongside of machine\n",
    "learning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2\n",
    "\n",
    "The following image shows a single, complete back-propagation cycle for the XOR example [1,1] -> 0. The identity\n",
    "function f(x) = x was used as the activation function. The boxed values are the updated weights for the corresponding\n",
    "weights in the matrix.\n",
    "\n",
    "(If this image doesn't show up it can be found in my repo under homework04)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('XOR.JPG')\n",
    "image.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3\n",
    "\n",
    "The following code shows a Keras-based CNN for the fashion MNIST dataset using the best architecture and \n",
    "hyperparameters that I could find. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=200)\n",
    "model.evaluate(test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Many different network variations from different hyperparameters to different conv2D filters to additional maxpooling\n",
    "were all tested, and this network gives the best result found with an accuracy of 99.24%. The key changes made were\n",
    "giving the hidden layer 128 units and making the batch size 200."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}