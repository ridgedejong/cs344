{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1\n",
    "\n",
    "The code below implements a spam filter based on Paul Graham's \"A Plan for Spam\". A spam and not spam corpus were\n",
    "given as test cases to test for spam. This code prints the probability tables for all the unique words in these\n",
    "corpora, and whether or not the messages in these corpora are considered spam.\n",
    "\n",
    "This approach is Bayesian because it uses Bayes Rule to calculate the probability of an event (email being spam)\n",
    "given certain conditions (individual words). The spam probabilities of each individual word are combined to give\n",
    "the overall spam probability of an email. Words can positively or negatively affect this probability, where good\n",
    "words reduce the spam probability while bad words increase it.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# test messages for spam and not spam in order to determine spam probabilities\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "\n",
    "# This function returns a dictionary with words as the keys and spam probabilities as the values\n",
    "def create_probabilityHT(spam, ham):\n",
    "    # initialize counters for spam and non-spam messages\n",
    "    nbad = 0\n",
    "    ngood = 0\n",
    "    # initialize list to record all unique words used\n",
    "    allwords = []\n",
    "    # initialize a dictionary of bad words\n",
    "    bad = {}\n",
    "    for phrase in spam:\n",
    "        nbad += 1\n",
    "        # count how many times each word is used\n",
    "        for word in phrase:\n",
    "            # make everything lowercase for uniformity\n",
    "            word = word.lower()\n",
    "            if bool(bad.get(word)):\n",
    "                bad[word] = bad[word] + 1\n",
    "            else:\n",
    "                bad[word] = 1\n",
    "            if word not in allwords:\n",
    "                allwords.append(word)\n",
    "    # initialize a dictionary of good words\n",
    "    good = {}\n",
    "    for phrase in ham:\n",
    "        ngood += 1\n",
    "        # count how many times each word is used\n",
    "        for word in phrase:\n",
    "            # make everything lowercase for uniformity\n",
    "            word = word.lower()\n",
    "            if bool(good.get(word)):\n",
    "                good[word] = good[word] + 1\n",
    "            else:\n",
    "                good[word] = 1\n",
    "            if word not in allwords:\n",
    "                allwords.append(word)\n",
    "    # initialize probability dictionary for all unique words\n",
    "    probabilities = {}\n",
    "    for word in allwords:\n",
    "        if bool(good.get(word)):\n",
    "            # weight good words more than bad words\n",
    "            g = 2 * good[word]\n",
    "        else:\n",
    "            g = 0\n",
    "        if bool(bad.get(word)):\n",
    "            b = bad[word]\n",
    "        else:\n",
    "            b = 0\n",
    "        # threshold of 1 so every word is evaluated\n",
    "        # calculate the probability that a word is spam based on the number of occurrences and number of good and bad messages\n",
    "        probabilities[word] = max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "    return probabilities\n",
    "\n",
    "# none of our test messages are 15+ words --> use all of them in test\n",
    "# This function determines the probability that a message is spam based on the individual probability of each word being spam\n",
    "def is_spam(message, dict):\n",
    "    # keep track of words used so each one is used once\n",
    "    usedwords = []\n",
    "    prod = 0\n",
    "    comp_prod = 0\n",
    "    first = True\n",
    "    for word in message:\n",
    "        # make everything lowercase for uniformity\n",
    "        word = word.lower()\n",
    "        if word not in usedwords:\n",
    "            # first time through loop is different so that you don't multiply by 0\n",
    "            if first:\n",
    "                prod = dict[word]\n",
    "                comp_prod = 1 - prod\n",
    "                first = False\n",
    "            else:\n",
    "                # multiply all the probabilities together\n",
    "                prod *= dict[word]\n",
    "                # multiply all the complements together\n",
    "                comp_prod *= 1 - dict[word]\n",
    "            usedwords.append(word)\n",
    "    # calculate combined probability\n",
    "    if prod / (prod + comp_prod) > 0.9:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "hash = create_probabilityHT(spam_corpus, ham_corpus)\n",
    "test1 = is_spam(spam_corpus[0], hash)\n",
    "test2 = is_spam(spam_corpus[1], hash)\n",
    "test3 = is_spam(ham_corpus[0], hash)\n",
    "test4 = is_spam(ham_corpus[1], hash)\n",
    "\n",
    "print(hash)\n",
    "print(\"First message spam? \", test1)\n",
    "print(\"Second message spam? \", test2)\n",
    "print(\"Third message spam? \", test3)\n",
    "print(\"Fourth message spam? \", test4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'i': 0.5, 'am': 0.99, 'spam': 0.99, 'do': 0.3333333333333333, 'not': 0.99, 'like': 0.3333333333333333, 'that': 0.99, 'spamiam': 0.99, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01}\n",
      "First message spam?  True\n",
      "Second message spam?  True\n",
      "Third message spam?  False\n",
      "Fourth message spam?  False\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2\n",
    "\n",
    "This problem uses the domain from Figure 14.12 of the AIMA text. The full joint probability distribution for\n",
    "this domain has 2^4 - 1 = 15 independent values if no conditional independence. This is because there are 4\n",
    "variables that each have 2 possible states, but they must all sum to 1 which removes an independent value.\n",
    "The number of independent values for the Bayesian network of this domain is different because it implies that\n",
    "Sprinkler and Rain depend on Cloudy, and in turn WetGrass depends on Sprinkler and Rain. Therefore, Cloudy has\n",
    "1 independent value, Sprinkler and Rain both have 2 based on the value of Cloudy, and WetGrass has 4 based on the\n",
    "value of Sprinkler and Rain, resulting in a total of 9 independent values, which is much better than the\n",
    "original 15 independent values in the full joint probability distribution.\n",
    "\n",
    "The code below shows the implementation of the Bayesian network for this domain, along with different probability\n",
    "calculations. These calculations were also done by hand and can be found on the sheet submitted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from probability import BayesNet, enumeration_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA - Fig. 14.12\n",
    "weather = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.0})\n",
    "    ])\n",
    "\n",
    "# Compute P(Cloudy).\n",
    "print(enumeration_ask('Cloudy', dict(), weather).show_approx())\n",
    "# Compute P(Sprinkler | cloudy).\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), weather).show_approx())\n",
    "# Compute P(Cloudy | the sprinkler is running and it's not raining).\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), weather).show_approx())\n",
    "# Compute P(WetGrass | it's cloudy, the sprinkler is running and it's raining).\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), weather).show_approx())\n",
    "# Compute P(Cloudy | grass is not wet).\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), weather).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}